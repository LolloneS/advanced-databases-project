# Advanced Databases 2CFU Project's Report
# Global Commodity Trade Statistics 
# Lorenzo Soligo - 806954

## Abstract
In this report I will compare the performances of a MongoDB database which uses some collections linked with references versus a MongoDB database using a one-collection embedded-document structure, whilst working with a huge dataset (~1GB, 8+ million rows) representing trades statistics for many countries, with and without indexes.

## Dataset
[Global Commodity Trade Statistics](https://www.kaggle.com/unitednations/global-commodity-trade-statistics) by [United Nations](https://www.kaggle.com/unitednations)

### Fields
The dataset fields are:
* `country_or_area`:
  * name of the country or area the trade refers to
* `year`:
  * year in which the trade was done
* `comm_code`
  * code of the commodity traded
* `commodity`
  * name of the commodity traded
* `flow`
  * flow of the trade: Import, Export, ...
* `trade_usd`
  * amount of the trade, in US dollars
* `weight_kg`
  * weight of the commodity traded, in kilograms
* `quantity_name`
  * type of quantity (e.g. number of items, weight in kilograms, ...)
* `quantity`
  * number representing the quantity (e.g. number of items = 5)
* `category`
  * category of the trade




## Single collection, embedded structure

### Modeling the dataset

Modeling the dataset requires thinking about the best way to embed the fields in order to achieve clarity, ease of use and good performance.

After some reasoning, I think this is one of the best choices that could be made for the dataset. 
Every document represents a single trade.

* `ID` (generated by Mongo)
* `country_or_area`
* `year`
* `commodity`
  - `name`
  - `code`
  - `category`
* `trade_details`
  * `flow`
  * `weight_kg`
  * `trade_usd`
  * `quantity`
  * `quantity_name`



#### Sample document

```json
{
    "_id" : ObjectId("5b06df5f0cea1a1aa46b4ce2"),
 	"country_or_area" : "Afghanistan",
 	"year" : "2016",
 	"commodity" : {
        "name" : "Sheep, live",
        "code" : "010410",
        "category" : "01_live_animals"
    },
 	"trade_details" : {
        "flow" : "Export",
        "weight_kg" : "2339",
        "trade_usd" : "6088",
        "quantity" : "51",
        "quantity_name" : "Number of items"
    }
}    
```





## Two collections with references

### Document structure (example)

Structuring the database using more than one collection lets us divide the *commodities* from the rest of the data regarding the trades, giving us the advantage of saving space - since many commodities are repeated thousands of times over the dataset's millions of rows

The rows will be thus splitted in two collections this way:

1. **trades**

* `ID` (generated by Mongo)
* `country_or_area`
* `year`
* `commodity`
* `trade_details`
  - `flow`
  - `weight_kg`
  - `trade_usd`
  - `quantity`
  - `quantity_name`

2. **commodities**

* `name`
* `code`
* `category`



## Time spent to parse and import the dataset

|            Single collection            | Two collections |
| :-------------------------------------: | :-------------: |
| Using a Python script and PyMongo: 420s |      TODO       |



## Time spent to create the indexes

| Field \ Database  | Embedded | Reference |
| ----------------- | -------- | --------- |
| `country_or_area` | 32s      | TODO      |
| `commodity.name`  | 42s      | TODO      |
| `commodity.code`  | 36s      | TODO      |
| `year`            | 39s      | TODO      |



## Execution time for the selected queries

#### Computer specs:
- Intel Core i5-6300U (low voltage laptop CPU)
- 8GB RAM DDR4
- 512GB NVMe SSD 




#### 1. Find for each year the country whose Export gain is highest
| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |   10s    |      TODO       |
| **Without Indexes** |   11s    |      TODO       |


#### 2. For each year, find the country which traded more kilograms of *010511*
| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |  0.05s   |      TODO       |
| **Without Indexes** |    6s    |      TODO       |


#### 3. Find the year in which more money was traded across all countries
| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |   14s    |      TODO       |
| **Without Indexes** |   15s    |      TODO       |


#### 4. Find out whether Canada traded more sheeps or goats alive
| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |   0.5s   |      TODO       |
| **Without Indexes** |    7s    |      TODO       |

#### 5. Find all the countries that have not traded *010600* or *010519* in 1998

| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |   TODO   |      TODO       |
| **Without Indexes** |   TODO   |      TODO       |

#### 6. Find the most expensive trade for every year and for each country 

| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |   TODO   |      TODO       |
| **Without Indexes** |   TODO   |      TODO       |

#### 7. Find out whether Italy traded more goats than Canada

| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |   TODO   |      TODO       |
| **Without Indexes** |   TODO   |      TODO       |

#### 8. Find all the categories

| Indexes \ DB        | Embedded | Two collections |
| ------------------- | :------: | :-------------: |
| **With Indexes**    |   TODO   |      TODO       |
| **Without Indexes** |   TODO   |      TODO       |



## Conclusions







## Some extra stuff

I created some Python scripts in order to parse and import the dataset into MongoDB.

I also tried to automate the process of setting the database up, creating indexes and running the queries as much as possible. This also helped me in measuring the time taken by every single step.




